{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM--------------------------------------------------------------------\n",
      "(1) train_test_split\n",
      "\n",
      "tp :  2  fn :  7  fp :  4  tn :  18\n",
      "\n",
      "accuracy=0.645161\n",
      "precision=0.333333\n",
      "recall=0.222222\n",
      "f1_score=0.266667\n",
      "\n",
      "(2) K-Flod cross validation\n",
      "\n",
      "tp :  3  fn :  3  fp :  4  tn :  13\n",
      "tp :  4  fn :  4  fp :  6  tn :  9\n",
      "tp :  2  fn :  7  fp :  2  tn :  12\n",
      "tp :  5  fn :  3  fp :  6  tn :  9\n",
      "\n",
      "average_accuracy =  0.6195652173913043\n",
      "average_precision =  0.4457792207792208\n",
      "average_recall =  0.4618055555555556\n",
      "average_f1_score =  0.43499775078722447\n",
      "\n",
      "LogisticRegression------------------------------------------------------\n",
      "(1) train_test_split\n",
      "\n",
      "tp :  2  fn :  4  fp :  8  tn :  14\n",
      "\n",
      "accuracy=0.571429\n",
      "precision=0.200000\n",
      "recall=0.333333\n",
      "f1_score=0.250000\n",
      "\n",
      "(2) K-Flod cross validation\n",
      "\n",
      "tp :  2  fn :  14  fp :  6  tn :  24\n",
      "tp :  2  fn :  13  fp :  7  tn :  24\n",
      "\n",
      "average_accuracy =  0.5652173913043478\n",
      "average_precision =  0.2361111111111111\n",
      "average_recall =  0.12916666666666665\n",
      "average_f1_score =  0.16666666666666669\n",
      "\n",
      "Random Forest-------------------------------------------------------\n",
      "(1) train_test_split\n",
      "\n",
      "tp :  2  fn :  4  fp :  1  tn :  12\n",
      "\n",
      "accuracy=0.736842\n",
      "precision=0.666667\n",
      "recall=0.333333\n",
      "f1_score=0.444444\n",
      "\n",
      "(2) K-Flod cross validation\n",
      "\n",
      "tp :  3  fn :  3  fp :  3  tn :  10\n",
      "tp :  5  fn :  2  fp :  3  tn :  9\n",
      "tp :  1  fn :  2  fp :  3  tn :  12\n",
      "tp :  4  fn :  6  fp :  1  tn :  7\n",
      "tp :  2  fn :  3  fp :  4  tn :  9\n",
      "\n",
      "average_accuracy =  0.6730994152046784\n",
      "average_precision =  0.5016666666666667\n",
      "average_recall =  0.4695238095238095\n",
      "average_f1_score =  0.4698701298701299\n"
     ]
    }
   ],
   "source": [
    "#csv 파일 읽어서 sql파일에 넣기\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "def load_db_score_data():\n",
    "    xlfile = 'C:/Users\\yoon2/datascience/db_score_3_labels.xlsx'\n",
    "    #xlfile = './datascience/db_score_3_labels.xlsx'\n",
    "    db_score = pd.read_excel(xlfile)\n",
    "    \n",
    "    #db connection 생성\n",
    "    conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    #겹칠 경우\n",
    "    drop_sql = \"\"\"drop table if exists db_score\"\"\"\n",
    "    curs.execute(drop_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    #직접 데이터프레임으로부터 테이블을 만들고 입력 하는 모듈\n",
    "    import sqlalchemy\n",
    "    database_username = 'root'\n",
    "    database_password = 'taeyoon!'\n",
    "    database_ip = 'localhost'\n",
    "    database_name = 'datascienceassignment4'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format(database_username,database_password,database_ip,database_name))\n",
    "    \n",
    "    #db_score 테이블 생성 + 데이터 입력\n",
    "    db_score.to_sql(con=database_connection, name='db_score',if_exists='replace')\n",
    "    \n",
    "load_db_score_data()\n",
    "\n",
    "conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql=\"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "\n",
    "#fetchone이 메모리요소에서 보면 바람직하나 데이터양이 적어 fetchall사용\n",
    "data=curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "#딕셔너리 형태가 튜플 형태의 리스트로 바뀐다.\n",
    "X=[(t['homework'],t['discussion'],t['midterm'])for t in data]\n",
    "\n",
    "#tuple의 리스트가 numpy로 바뀐다.\n",
    "import numpy as np\n",
    "X=np.array(X)\n",
    "\n",
    "y=[1 if (t['grade']=='B') else -1 for t in data]\n",
    "y=np.array(y)\n",
    "\n",
    "#----------------------------SVM--------------------------------------------------\n",
    "print(\"SVM--------------------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.33, random_state=42) #보통 42로 고정\n",
    "\n",
    "'''\n",
    "#특성 스케일 - 특성 간 값의 범위 줄이\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "'''\n",
    "#훈련셋으로 SVM 훈련\n",
    "from sklearn.svm import SVC\n",
    "svm_model=SVC(kernel='rbf',C=8,gamma=0.1)\n",
    "svm_model.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict = svm_model.predict(X_test) # 테스트\n",
    " \n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for y, yp in zip(y,y_predict) :\n",
    "            if (y == 1 and yp == 1):\n",
    "                tp += 1\n",
    "            elif(y == 1 and yp == -1):\n",
    "                fn += 1\n",
    "            elif(y== -1 and yp == 1) : \n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = (tp)/(tp+fp)\n",
    "    recall = (tp) / (tp+fn)\n",
    "    if(recall==0):\n",
    "        print(\"recall = 0 ,예외처리\")\n",
    "        f1_score=0\n",
    "    else:\n",
    "        f1_score = 2*precision*recall / (precision + recall)\n",
    "    return accuracy,precision,recall,f1_score\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "print(\"precision=%f\"%prec)\n",
    "print(\"recall=%f\"%rec)\n",
    "print(\"f1_score=%f\\n\"%f1)\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "\n",
    "    #훈련셋으로 SVM 훈련\n",
    "    svm_model=SVC(kernel='rbf',C=8,gamma=0.1)\n",
    "    svm_model.fit(X_train,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict = svm_model.predict(X_test) # 테스트\n",
    "    acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "import statistics\n",
    "\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"average_precision = \",statistics.mean(precision))\n",
    "print(\"average_recall = \",statistics.mean(recall))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score))\n",
    "\n",
    "#----------------------------LogisticRegression------------------------------\n",
    "print(\"\\nLogisticRegression------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3, random_state=43) #보통 42로 고정\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ml=LogisticRegression(C=1000.0,random_state=0)\n",
    "ml.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict=ml.predict(X_test)\n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for y, yp in zip(y,y_predict) :\n",
    "            if (y == 1 and yp == 1):\n",
    "                tp += 1\n",
    "            elif(y == 1 and yp == -1):\n",
    "                fn += 1\n",
    "            elif(y== -1 and yp == 1) : \n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    \n",
    "    print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "\n",
    "    if(tp==0):\n",
    "        print(\"tp = 0 ,precision 예외처리\")\n",
    "        precision=0\n",
    "    else:\n",
    "        precision = (tp)/(tp+fp)\n",
    "    recall = (tp) / (tp+fn)\n",
    "    if(recall==0):\n",
    "        print(\"recall = 0 ,f1_score 예외처리\")\n",
    "        f1_score=0\n",
    "    else:\n",
    "        f1_score = 2*precision*recall / (precision + recall)\n",
    "\n",
    "    return accuracy,precision,recall,f1_score\n",
    "acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "print(\"precision=%f\"%prec)\n",
    "print(\"recall=%f\"%rec)\n",
    "print(\"f1_score=%f\\n\"%f1)\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=2, random_state=500, shuffle=True)\n",
    "#random_state 42에서 46으로 조정\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "\n",
    "    #훈련셋으로 LogisticRegression 훈련\n",
    "    ml=LogisticRegression(C=1000.0,random_state=0)\n",
    "    ml.fit(X_train,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict=ml.predict(X_test)\n",
    "    \n",
    "    acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "import statistics\n",
    "\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"average_precision = \",statistics.mean(precision))\n",
    "print(\"average_recall = \",statistics.mean(recall))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score))\n",
    "\n",
    "\n",
    "#----------------------------Random Forest------------------------------\n",
    "print(\"\\nRandom Forest-------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42) #보통 42로 고정\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict=rf.predict(X_test)\n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for y, yp in zip(y,y_predict) :\n",
    "            if (y == 1 and yp == 1):\n",
    "                tp += 1\n",
    "            elif(y == 1 and yp == -1):\n",
    "                fn += 1\n",
    "            elif(y== -1 and yp == 1) : \n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = (tp)/(tp+fp)\n",
    "    recall = (tp) / (tp+fn)\n",
    "    f1_score = 2*precision*recall / (precision + recall)\n",
    "    return accuracy,precision,recall,f1_score\n",
    "acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "print(\"precision=%f\"%prec)\n",
    "print(\"recall=%f\"%rec)\n",
    "print(\"f1_score=%f\\n\"%f1)\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "    \n",
    "    #훈련셋으로 RandomForest 훈련\n",
    "    rf=RandomForestClassifier(random_state=0)\n",
    "    rf.fit(X_train,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict=rf.predict(X_test)\n",
    "    \n",
    "    acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "import statistics\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"average_precision = \",statistics.mean(precision))\n",
    "print(\"average_recall = \",statistics.mean(recall))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM--------------------------------------------------------------------\n",
      "(1) train_test_split\n",
      "\n",
      "\n",
      "accuracy=0.652174\n",
      "A\n",
      "precision=0.555556\n",
      "recall=0.555556\n",
      "f1_score=0.555556\n",
      "\n",
      "B\n",
      "precision=0.375000\n",
      "recall=0.500000\n",
      "f1_score=0.428571\n",
      "\n",
      "C\n",
      "precision=0.500000\n",
      "recall=0.875000\n",
      "f1_score=0.636364\n",
      "\n",
      "(2) K-Flod cross validation\n",
      "\n",
      "\n",
      "average_accuracy =  0.6413043478260869\n",
      "A\n",
      "average_precision =  0.4618055555555556\n",
      "average_recall =  0.6404761904761905\n",
      "average_f1_score =  0.523202614379085\n",
      "B\n",
      "average_precision =  0.46875\n",
      "average_recall =  0.5520833333333334\n",
      "average_f1_score =  0.49661654135338346\n",
      "C\n",
      "average_precision =  0.4725274725274725\n",
      "average_recall =  0.7256944444444444\n",
      "average_f1_score =  0.5695065803761455\n",
      "\n",
      "LogisticRegression------------------------------------------------------\n",
      "(1) train_test_split\n",
      "\n",
      "\n",
      "accuracy=0.608696\n",
      "A\n",
      "precision=0.533333\n",
      "recall=0.800000\n",
      "f1_score=0.640000\n",
      "\n",
      "B\n",
      "precision=0.142857\n",
      "recall=0.250000\n",
      "f1_score=0.181818\n",
      "\n",
      "C\n",
      "precision=0.500000\n",
      "recall=0.555556\n",
      "f1_score=0.526316\n",
      "\n",
      "(2) K-Flod cross validation\n",
      "\n",
      "\n",
      "average_accuracy =  0.6630824372759856\n",
      "A\n",
      "average_precision =  0.49381868131868134\n",
      "average_recall =  0.7321428571428571\n",
      "average_f1_score =  0.5737934904601572\n",
      "B\n",
      "average_precision =  0.5\n",
      "average_recall =  0.5454545454545454\n",
      "average_f1_score =  0.5166329966329967\n",
      "C\n",
      "average_precision =  0.5014245014245015\n",
      "average_recall =  0.7606837606837608\n",
      "average_f1_score =  0.5860805860805861\n",
      "\n",
      "Random Forest-------------------------------------------------------\n",
      "(1) train_test_split\n",
      "\n",
      "\n",
      "accuracy=0.695652\n",
      "A\n",
      "precision=0.625000\n",
      "recall=0.555556\n",
      "f1_score=0.588235\n",
      "\n",
      "B\n",
      "precision=0.444444\n",
      "recall=0.666667\n",
      "f1_score=0.533333\n",
      "\n",
      "C\n",
      "precision=0.538462\n",
      "recall=0.875000\n",
      "f1_score=0.666667\n",
      "\n",
      "(2) K-Flod cross validation\n",
      "\n",
      "\n",
      "average_accuracy =  0.6637992831541218\n",
      "A\n",
      "average_precision =  0.49122807017543857\n",
      "average_recall =  0.7478354978354979\n",
      "average_f1_score =  0.5879928315412186\n",
      "B\n",
      "average_precision =  0.48148148148148145\n",
      "average_recall =  0.39057239057239057\n",
      "average_f1_score =  0.42657952069716776\n",
      "C\n",
      "average_precision =  0.506578947368421\n",
      "average_recall =  0.8724747474747475\n",
      "average_f1_score =  0.6331569664902998\n"
     ]
    }
   ],
   "source": [
    "#csv 파일 읽어서 sql파일에 넣기\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "def load_db_score_data():\n",
    "    xlfile = 'C:/Users\\yoon2/datascience/db_score_3_labels.xlsx'\n",
    "    #xlfile = './datascience/db_score_3_labels.xlsx'\n",
    "    db_score = pd.read_excel(xlfile)\n",
    "    \n",
    "    #db connection 생성\n",
    "    conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    #겹칠 경우\n",
    "    drop_sql = \"\"\"drop table if exists db_score\"\"\"\n",
    "    curs.execute(drop_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    #직접 데이터프레임으로부터 테이블을 만들고 입력 하는 모듈\n",
    "    import sqlalchemy\n",
    "    database_username = 'root'\n",
    "    database_password = 'taeyoon!'\n",
    "    database_ip = 'localhost'\n",
    "    database_name = 'datascienceassignment4'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format(database_username,database_password,database_ip,database_name))\n",
    "    \n",
    "    #db_score 테이블 생성 + 데이터 입력\n",
    "    db_score.to_sql(con=database_connection, name='db_score',if_exists='replace')\n",
    "    \n",
    "load_db_score_data()\n",
    "\n",
    "conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql=\"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "\n",
    "#fetchone이 메모리요소에서 보면 바람직하나 데이터양이 적어 fetchall사용\n",
    "data=curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "#딕셔너리 형태가 튜플 형태의 리스트로 바뀐다.\n",
    "X=[(t['homework'],t['discussion'],t['midterm'])for t in data]\n",
    "\n",
    "#tuple의 리스트가 numpy로 바뀐다.\n",
    "import numpy as np\n",
    "X=np.array(X)\n",
    "\n",
    "y=[(t['grade']) for t in data]\n",
    "y=np.array(y)\n",
    "\n",
    "#----------------------------SVM--------------------------------------------------\n",
    "print(\"SVM--------------------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=42) #보통 42로 고정\n",
    "\n",
    "'''\n",
    "#특성 스케일 - 특성 간 값의 범위 줄이\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "'''\n",
    "#훈련셋으로 SVM 훈련\n",
    "from sklearn.svm import SVC\n",
    "svm_model=SVC(kernel='rbf',C=8,gamma=0.1)\n",
    "svm_model.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict = svm_model.predict(X_test) # 테스트\n",
    " \n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    \n",
    "    #A\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'A' and yp == 'A'):\n",
    "            tp += 1\n",
    "        elif((y == 'A' and yp == 'B')or(y == 'A' and yp == 'C')):\n",
    "            fn += 1 \n",
    "        elif((y == 'B' and yp == 'B')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1      \n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_a = (tp)/(tp+fp)\n",
    "    recall_a = (tp) / (tp+fn)\n",
    "    f1_score_a = 2*precision_a*recall_a / (precision_a + recall_a)\n",
    "\n",
    "    #B\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'B' and yp == 'B'):\n",
    "            tp += 1\n",
    "        elif((y == 'B' and yp == 'A')or(y == 'B' and yp == 'C')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1         \n",
    "\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_b = (tp)/(tp+fp)\n",
    "    recall_b = (tp) / (tp+fn)\n",
    "    f1_score_b = 2*precision_b*recall_b / (precision_b + recall_b)\n",
    "\n",
    "    #C\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'C' and yp == 'C'):\n",
    "            tp += 1\n",
    "        elif((y == 'C' and yp == 'A')or(y == 'C' and yp == 'B')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'B' and yp == 'B')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_c = (tp)/(tp+fp)\n",
    "    recall_c = (tp) / (tp+fn)\n",
    "    f1_score_c = 2*precision_c*recall_c / (precision_c + recall_c)\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy,precision_a,precision_b,precision_c,recall_a,recall_b,recall_c,f1_score_a,f1_score_b,f1_score_c\n",
    "\n",
    "acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "\n",
    "print(\"A\")\n",
    "print(\"precision=%f\"%prec_a)\n",
    "print(\"recall=%f\"%rec_a)\n",
    "print(\"f1_score=%f\\n\"%f1_a)\n",
    "\n",
    "print(\"B\")\n",
    "print(\"precision=%f\"%prec_b)\n",
    "print(\"recall=%f\"%rec_b)\n",
    "print(\"f1_score=%f\\n\"%f1_b)\n",
    "\n",
    "print(\"C\")\n",
    "print(\"precision=%f\"%prec_c)\n",
    "print(\"recall=%f\"%rec_c)\n",
    "print(\"f1_score=%f\\n\"%f1_c)\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision_a = []\n",
    "precision_b = []\n",
    "precision_c = []\n",
    "recall_a = []\n",
    "recall_b = []\n",
    "recall_c = []\n",
    "f1_score_a = []\n",
    "f1_score_b = []\n",
    "f1_score_c = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "\n",
    "    #훈련셋으로 SVM 훈련\n",
    "    svm_model=SVC(kernel='rbf',C=8,gamma=0.1)\n",
    "    svm_model.fit(X_train,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict = svm_model.predict(X_test) # 테스트\n",
    "    acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c= classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision_a.append(prec_a)\n",
    "    precision_b.append(prec_b)\n",
    "    precision_c.append(prec_c)\n",
    "    recall_a.append(rec_a)\n",
    "    recall_b.append(rec_b)\n",
    "    recall_c.append(rec_c)\n",
    "    f1_score_a.append(f1_a)\n",
    "    f1_score_b.append(f1_b)\n",
    "    f1_score_c.append(f1_c)\n",
    "\n",
    "import statistics\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"A\")\n",
    "print(\"average_precision = \",statistics.mean(precision_a))\n",
    "print(\"average_recall = \",statistics.mean(recall_a))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_a))\n",
    "print(\"B\")\n",
    "print(\"average_precision = \",statistics.mean(precision_b))\n",
    "print(\"average_recall = \",statistics.mean(recall_b))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_b))\n",
    "print(\"C\")\n",
    "print(\"average_precision = \",statistics.mean(precision_c))\n",
    "print(\"average_recall = \",statistics.mean(recall_c))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_c))\n",
    "\n",
    "#----------------------------LogisticRegression------------------------------\n",
    "print(\"\\nLogisticRegression------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=43) #보통 42로 고정\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ml=LogisticRegression(C=1000.0,random_state=0,max_iter=10000)\n",
    "ml.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict=ml.predict(X_test)\n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    \n",
    "    #A\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'A' and yp == 'A'):\n",
    "            tp += 1\n",
    "        elif((y == 'A' and yp == 'B')or(y == 'A' and yp == 'C')):\n",
    "            fn += 1 \n",
    "        elif((y == 'B' and yp == 'B')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1      \n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_a = (tp)/(tp+fp)\n",
    "    recall_a = (tp) / (tp+fn)\n",
    "    f1_score_a = 2*precision_a*recall_a / (precision_a + recall_a)\n",
    "\n",
    "    #B\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'B' and yp == 'B'):\n",
    "            tp += 1\n",
    "        elif((y == 'B' and yp == 'A')or(y == 'B' and yp == 'C')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1         \n",
    "\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_b = (tp)/(tp+fp)\n",
    "    recall_b = (tp) / (tp+fn)\n",
    "    f1_score_b = 2*precision_b*recall_b / (precision_b + recall_b)\n",
    "\n",
    "    #C\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'C' and yp == 'C'):\n",
    "            tp += 1\n",
    "        elif((y == 'C' and yp == 'A')or(y == 'C' and yp == 'B')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'B' and yp == 'B')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_c = (tp)/(tp+fp)\n",
    "    recall_c = (tp) / (tp+fn)\n",
    "    f1_score_c = 2*precision_c*recall_c / (precision_c + recall_c)\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy,precision_a,precision_b,precision_c,recall_a,recall_b,recall_c,f1_score_a,f1_score_b,f1_score_c\n",
    "\n",
    "acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "\n",
    "print(\"A\")\n",
    "print(\"precision=%f\"%prec_a)\n",
    "print(\"recall=%f\"%rec_a)\n",
    "print(\"f1_score=%f\\n\"%f1_a)\n",
    "\n",
    "print(\"B\")\n",
    "print(\"precision=%f\"%prec_b)\n",
    "print(\"recall=%f\"%rec_b)\n",
    "print(\"f1_score=%f\\n\"%f1_b)\n",
    "\n",
    "print(\"C\")\n",
    "print(\"precision=%f\"%prec_c)\n",
    "print(\"recall=%f\"%rec_c)\n",
    "print(\"f1_score=%f\\n\"%f1_c)\n",
    "\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision_a = []\n",
    "precision_b = []\n",
    "precision_c = []\n",
    "recall_a = []\n",
    "recall_b = []\n",
    "recall_c = []\n",
    "f1_score_a = []\n",
    "f1_score_b = []\n",
    "f1_score_c = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=3, random_state=500, shuffle=True)\n",
    "#random_state 42에서 46으로 조정\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "    #특성 스케일 - 특성 간 값의 범위 줄이\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc=StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    #훈련셋으로 LogisticRegression 훈련\n",
    "    ml=LogisticRegression(C=1000,solver='lbfgs',random_state=42)\n",
    "    ml.fit(X_train_std,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict=ml.predict(X_test_std)\n",
    "    \n",
    "    acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision_a.append(prec_a)\n",
    "    precision_b.append(prec_b)\n",
    "    precision_c.append(prec_c)\n",
    "    recall_a.append(rec_a)\n",
    "    recall_b.append(rec_b)\n",
    "    recall_c.append(rec_c)\n",
    "    f1_score_a.append(f1_a)\n",
    "    f1_score_b.append(f1_b)\n",
    "    f1_score_c.append(f1_c)\n",
    "\n",
    "import statistics\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"A\")\n",
    "print(\"average_precision = \",statistics.mean(precision_a))\n",
    "print(\"average_recall = \",statistics.mean(recall_a))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_a))\n",
    "print(\"B\")\n",
    "print(\"average_precision = \",statistics.mean(precision_b))\n",
    "print(\"average_recall = \",statistics.mean(recall_b))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_b))\n",
    "print(\"C\")\n",
    "print(\"average_precision = \",statistics.mean(precision_c))\n",
    "print(\"average_recall = \",statistics.mean(recall_c))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_c))\n",
    "\n",
    "\n",
    "#----------------------------Random Forest------------------------------\n",
    "print(\"\\nRandom Forest-------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=42) #보통 42로 고정\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict=rf.predict(X_test)\n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    \n",
    "    #A\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'A' and yp == 'A'):\n",
    "            tp += 1\n",
    "        elif((y == 'A' and yp == 'B')or(y == 'A' and yp == 'C')):\n",
    "            fn += 1 \n",
    "        elif((y == 'B' and yp == 'B')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1      \n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_a = (tp)/(tp+fp)\n",
    "    recall_a = (tp) / (tp+fn)\n",
    "    f1_score_a = 2*precision_a*recall_a / (precision_a + recall_a)\n",
    "\n",
    "    #B\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'B' and yp == 'B'):\n",
    "            tp += 1\n",
    "        elif((y == 'B' and yp == 'A')or(y == 'B' and yp == 'C')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1         \n",
    "\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_b = (tp)/(tp+fp)\n",
    "    recall_b = (tp) / (tp+fn)\n",
    "    f1_score_b = 2*precision_b*recall_b / (precision_b + recall_b)\n",
    "\n",
    "    #C\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'C' and yp == 'C'):\n",
    "            tp += 1\n",
    "        elif((y == 'C' and yp == 'A')or(y == 'C' and yp == 'B')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'B' and yp == 'B')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_c = (tp)/(tp+fp)\n",
    "    recall_c = (tp) / (tp+fn)\n",
    "    f1_score_c = 2*precision_c*recall_c / (precision_c + recall_c)\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy,precision_a,precision_b,precision_c,recall_a,recall_b,recall_c,f1_score_a,f1_score_b,f1_score_c\n",
    "\n",
    "acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "\n",
    "print(\"A\")\n",
    "print(\"precision=%f\"%prec_a)\n",
    "print(\"recall=%f\"%rec_a)\n",
    "print(\"f1_score=%f\\n\"%f1_a)\n",
    "\n",
    "print(\"B\")\n",
    "print(\"precision=%f\"%prec_b)\n",
    "print(\"recall=%f\"%rec_b)\n",
    "print(\"f1_score=%f\\n\"%f1_b)\n",
    "\n",
    "print(\"C\")\n",
    "print(\"precision=%f\"%prec_c)\n",
    "print(\"recall=%f\"%rec_c)\n",
    "print(\"f1_score=%f\\n\"%f1_c)\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision_a = []\n",
    "precision_b = []\n",
    "precision_c = []\n",
    "recall_a = []\n",
    "recall_b = []\n",
    "recall_c = []\n",
    "f1_score_a = []\n",
    "f1_score_b = []\n",
    "f1_score_c = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "    \n",
    "    #훈련셋으로 RandomForest 훈련\n",
    "    rf=RandomForestClassifier(random_state=0)\n",
    "    rf.fit(X_train,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict=rf.predict(X_test)\n",
    "    \n",
    "    acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision_a.append(prec_a)\n",
    "    precision_b.append(prec_b)\n",
    "    precision_c.append(prec_c)\n",
    "    recall_a.append(rec_a)\n",
    "    recall_b.append(rec_b)\n",
    "    recall_c.append(rec_c)\n",
    "    f1_score_a.append(f1_a)\n",
    "    f1_score_b.append(f1_b)\n",
    "    f1_score_c.append(f1_c)\n",
    "\n",
    "import statistics\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"A\")\n",
    "print(\"average_precision = \",statistics.mean(precision_a))\n",
    "print(\"average_recall = \",statistics.mean(recall_a))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_a))\n",
    "print(\"B\")\n",
    "print(\"average_precision = \",statistics.mean(precision_b))\n",
    "print(\"average_recall = \",statistics.mean(recall_b))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_b))\n",
    "print(\"C\")\n",
    "print(\"average_precision = \",statistics.mean(precision_c))\n",
    "print(\"average_recall = \",statistics.mean(recall_c))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일 읽어서 sql파일에 넣기\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "def load_db_score_data():\n",
    "    #xlfile = 'C:/Users\\yoon2/datascience/db_score_3_labels.xlsx'\n",
    "    xlfile = './datascience/db_score_3_labels.xlsx'\n",
    "    db_score = pd.read_excel(xlfile)\n",
    "    \n",
    "    #db connection 생성\n",
    "    conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    #겹칠 경우\n",
    "    drop_sql = \"\"\"drop table if exists db_score\"\"\"\n",
    "    curs.execute(drop_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    #직접 데이터프레임으로부터 테이블을 만들고 입력 하는 모듈\n",
    "    import sqlalchemy\n",
    "    database_username = 'root'\n",
    "    database_password = 'taeyoon!'\n",
    "    database_ip = 'localhost'\n",
    "    database_name = 'datascienceassignment4'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format(database_username,database_password,database_ip,database_name))\n",
    "    \n",
    "    #db_score 테이블 생성 + 데이터 입력\n",
    "    db_score.to_sql(con=database_connection, name='db_score',if_exists='replace')\n",
    "    \n",
    "load_db_score_data()\n",
    "\n",
    "conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql=\"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "\n",
    "#fetchone이 메모리요소에서 보면 바람직하나 데이터양이 적어 fetchall사용\n",
    "data=curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "#딕셔너리 형태가 튜플 형태의 리스트로 바뀐다.\n",
    "X=[(t['homework'],t['discussion'],t['midterm'])for t in data]\n",
    "\n",
    "#tuple의 리스트가 numpy로 바뀐다.\n",
    "import numpy as np\n",
    "X=np.array(X)\n",
    "\n",
    "y=[(t['grade']) for t in data]\n",
    "y=np.array(y)\n",
    "\n",
    "#----------------------------SVM--------------------------------------------------\n",
    "print(\"SVM--------------------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=42) #보통 42로 고정\n",
    "\n",
    "'''\n",
    "#특성 스케일 - 특성 간 값의 범위 줄이\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "'''\n",
    "#훈련셋으로 SVM 훈련\n",
    "from sklearn.svm import SVC\n",
    "svm_model=SVC(kernel='rbf',C=8,gamma=0.1)\n",
    "svm_model.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict = svm_model.predict(X_test) # 테스트\n",
    " \n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    \n",
    "    #A\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'A' and yp == 'A'):\n",
    "            tp += 1\n",
    "        elif((y == 'A' and yp == 'B')or(y == 'A' and yp == 'C')):\n",
    "            fn += 1 \n",
    "        elif((y == 'B' and yp == 'B')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1      \n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_a = (tp)/(tp+fp)\n",
    "    recall_a = (tp) / (tp+fn)\n",
    "    f1_score_a = 2*precision_a*recall_a / (precision_a + recall_a)\n",
    "\n",
    "    #B\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'B' and yp == 'B'):\n",
    "            tp += 1\n",
    "        elif((y == 'B' and yp == 'A')or(y == 'B' and yp == 'C')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1         \n",
    "\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_b = (tp)/(tp+fp)\n",
    "    recall_b = (tp) / (tp+fn)\n",
    "    f1_score_b = 2*precision_b*recall_b / (precision_b + recall_b)\n",
    "\n",
    "    #C\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'C' and yp == 'C'):\n",
    "            tp += 1\n",
    "        elif((y == 'C' and yp == 'A')or(y == 'C' and yp == 'B')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'B' and yp == 'B')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_c = (tp)/(tp+fp)\n",
    "    recall_c = (tp) / (tp+fn)\n",
    "    f1_score_c = 2*precision_c*recall_c / (precision_c + recall_c)\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy,precision_a,precision_b,precision_c,recall_a,recall_b,recall_c,f1_score_a,f1_score_b,f1_score_c\n",
    "\n",
    "acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "\n",
    "print(\"A\")\n",
    "print(\"precision=%f\"%prec_a)\n",
    "print(\"recall=%f\"%rec_a)\n",
    "print(\"f1_score=%f\\n\"%f1_a)\n",
    "\n",
    "print(\"B\")\n",
    "print(\"precision=%f\"%prec_b)\n",
    "print(\"recall=%f\"%rec_b)\n",
    "print(\"f1_score=%f\\n\"%f1_b)\n",
    "\n",
    "print(\"C\")\n",
    "print(\"precision=%f\"%prec_c)\n",
    "print(\"recall=%f\"%rec_c)\n",
    "print(\"f1_score=%f\\n\"%f1_c)\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision_a = []\n",
    "precision_b = []\n",
    "precision_c = []\n",
    "recall_a = []\n",
    "recall_b = []\n",
    "recall_c = []\n",
    "f1_score_a = []\n",
    "f1_score_b = []\n",
    "f1_score_c = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "\n",
    "    #훈련셋으로 SVM 훈련\n",
    "    svm_model=SVC(kernel='rbf',C=8,gamma=0.1)\n",
    "    svm_model.fit(X_train,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict = svm_model.predict(X_test) # 테스트\n",
    "    acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c= classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision_a.append(prec_a)\n",
    "    precision_b.append(prec_b)\n",
    "    precision_c.append(prec_c)\n",
    "    recall_a.append(rec_a)\n",
    "    recall_b.append(rec_b)\n",
    "    recall_c.append(rec_c)\n",
    "    f1_score_a.append(f1_a)\n",
    "    f1_score_b.append(f1_b)\n",
    "    f1_score_c.append(f1_c)\n",
    "\n",
    "import statistics\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"A\")\n",
    "print(\"average_precision = \",statistics.mean(precision_a))\n",
    "print(\"average_recall = \",statistics.mean(recall_a))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_a))\n",
    "print(\"B\")\n",
    "print(\"average_precision = \",statistics.mean(precision_b))\n",
    "print(\"average_recall = \",statistics.mean(recall_b))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_b))\n",
    "print(\"C\")\n",
    "print(\"average_precision = \",statistics.mean(precision_c))\n",
    "print(\"average_recall = \",statistics.mean(recall_c))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_c))\n",
    "\n",
    "#----------------------------LogisticRegression------------------------------\n",
    "print(\"\\nLogisticRegression------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=43) #보통 42로 고정\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ml=LogisticRegression(C=1000.0,random_state=0,max_iter=10000)\n",
    "ml.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict=ml.predict(X_test)\n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    \n",
    "    #A\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'A' and yp == 'A'):\n",
    "            tp += 1\n",
    "        elif((y == 'A' and yp == 'B')or(y == 'A' and yp == 'C')):\n",
    "            fn += 1 \n",
    "        elif((y == 'B' and yp == 'B')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1      \n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_a = (tp)/(tp+fp)\n",
    "    recall_a = (tp) / (tp+fn)\n",
    "    f1_score_a = 2*precision_a*recall_a / (precision_a + recall_a)\n",
    "\n",
    "    #B\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'B' and yp == 'B'):\n",
    "            tp += 1\n",
    "        elif((y == 'B' and yp == 'A')or(y == 'B' and yp == 'C')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1         \n",
    "\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_b = (tp)/(tp+fp)\n",
    "    recall_b = (tp) / (tp+fn)\n",
    "    f1_score_b = 2*precision_b*recall_b / (precision_b + recall_b)\n",
    "\n",
    "    #C\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'C' and yp == 'C'):\n",
    "            tp += 1\n",
    "        elif((y == 'C' and yp == 'A')or(y == 'C' and yp == 'B')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'B' and yp == 'B')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_c = (tp)/(tp+fp)\n",
    "    recall_c = (tp) / (tp+fn)\n",
    "    f1_score_c = 2*precision_c*recall_c / (precision_c + recall_c)\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy,precision_a,precision_b,precision_c,recall_a,recall_b,recall_c,f1_score_a,f1_score_b,f1_score_c\n",
    "\n",
    "acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "\n",
    "print(\"A\")\n",
    "print(\"precision=%f\"%prec_a)\n",
    "print(\"recall=%f\"%rec_a)\n",
    "print(\"f1_score=%f\\n\"%f1_a)\n",
    "\n",
    "print(\"B\")\n",
    "print(\"precision=%f\"%prec_b)\n",
    "print(\"recall=%f\"%rec_b)\n",
    "print(\"f1_score=%f\\n\"%f1_b)\n",
    "\n",
    "print(\"C\")\n",
    "print(\"precision=%f\"%prec_c)\n",
    "print(\"recall=%f\"%rec_c)\n",
    "print(\"f1_score=%f\\n\"%f1_c)\n",
    "\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision_a = []\n",
    "precision_b = []\n",
    "precision_c = []\n",
    "recall_a = []\n",
    "recall_b = []\n",
    "recall_c = []\n",
    "f1_score_a = []\n",
    "f1_score_b = []\n",
    "f1_score_c = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=3, random_state=500, shuffle=True)\n",
    "#random_state 42에서 46으로 조정\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "    #특성 스케일 - 특성 간 값의 범위 줄이\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc=StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    #훈련셋으로 LogisticRegression 훈련\n",
    "    ml=LogisticRegression(C=1000,solver='lbfgs',random_state=42)\n",
    "    ml.fit(X_train_std,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict=ml.predict(X_test_std)\n",
    "    \n",
    "    acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision_a.append(prec_a)\n",
    "    precision_b.append(prec_b)\n",
    "    precision_c.append(prec_c)\n",
    "    recall_a.append(rec_a)\n",
    "    recall_b.append(rec_b)\n",
    "    recall_c.append(rec_c)\n",
    "    f1_score_a.append(f1_a)\n",
    "    f1_score_b.append(f1_b)\n",
    "    f1_score_c.append(f1_c)\n",
    "\n",
    "import statistics\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"A\")\n",
    "print(\"average_precision = \",statistics.mean(precision_a))\n",
    "print(\"average_recall = \",statistics.mean(recall_a))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_a))\n",
    "print(\"B\")\n",
    "print(\"average_precision = \",statistics.mean(precision_b))\n",
    "print(\"average_recall = \",statistics.mean(recall_b))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_b))\n",
    "print(\"C\")\n",
    "print(\"average_precision = \",statistics.mean(precision_c))\n",
    "print(\"average_recall = \",statistics.mean(recall_c))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_c))\n",
    "\n",
    "\n",
    "#----------------------------Random Forest------------------------------\n",
    "print(\"\\nRandom Forest-------------------------------------------------------\")\n",
    "print(\"(1) train_test_split\\n\")\n",
    "#(1) train_test_split\n",
    "\n",
    "#train data와 test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=42) #보통 42로 고정\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "#테스트셋을 가지고 성능 확인\n",
    "y_predict=rf.predict(X_test)\n",
    "\n",
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    \n",
    "    #A\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'A' and yp == 'A'):\n",
    "            tp += 1\n",
    "        elif((y == 'A' and yp == 'B')or(y == 'A' and yp == 'C')):\n",
    "            fn += 1 \n",
    "        elif((y == 'B' and yp == 'B')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1      \n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_a = (tp)/(tp+fp)\n",
    "    recall_a = (tp) / (tp+fn)\n",
    "    f1_score_a = 2*precision_a*recall_a / (precision_a + recall_a)\n",
    "\n",
    "    #B\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'B' and yp == 'B'):\n",
    "            tp += 1\n",
    "        elif((y == 'B' and yp == 'A')or(y == 'B' and yp == 'C')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'C' and yp == 'C')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1         \n",
    "\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_b = (tp)/(tp+fp)\n",
    "    recall_b = (tp) / (tp+fn)\n",
    "    f1_score_b = 2*precision_b*recall_b / (precision_b + recall_b)\n",
    "\n",
    "    #C\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for y, yp in zip(y_test,y_predict) :\n",
    "        if (y == 'C' and yp == 'C'):\n",
    "            tp += 1\n",
    "        elif((y == 'C' and yp == 'A')or(y == 'C' and yp == 'B')):\n",
    "            fn += 1\n",
    "        elif((y == 'A' and yp == 'A')or(y == 'B' and yp == 'B')) : \n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    #print(\"tp : \",tp,\" fn : \",fn,\" fp : \",fp,\" tn : \",tn)\n",
    "    precision_c = (tp)/(tp+fp)\n",
    "    recall_c = (tp) / (tp+fn)\n",
    "    f1_score_c = 2*precision_c*recall_c / (precision_c + recall_c)\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy,precision_a,precision_b,precision_c,recall_a,recall_b,recall_c,f1_score_a,f1_score_b,f1_score_c\n",
    "\n",
    "acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"\\naccuracy=%f\"%acc)\n",
    "\n",
    "print(\"A\")\n",
    "print(\"precision=%f\"%prec_a)\n",
    "print(\"recall=%f\"%rec_a)\n",
    "print(\"f1_score=%f\\n\"%f1_a)\n",
    "\n",
    "print(\"B\")\n",
    "print(\"precision=%f\"%prec_b)\n",
    "print(\"recall=%f\"%rec_b)\n",
    "print(\"f1_score=%f\\n\"%f1_b)\n",
    "\n",
    "print(\"C\")\n",
    "print(\"precision=%f\"%prec_c)\n",
    "print(\"recall=%f\"%rec_c)\n",
    "print(\"f1_score=%f\\n\"%f1_c)\n",
    "\n",
    "#(2)K-Flod cross validation\n",
    "print(\"(2) K-Flod cross validation\\n\")\n",
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "accuracy= []\n",
    "precision_a = []\n",
    "precision_b = []\n",
    "precision_c = []\n",
    "recall_a = []\n",
    "recall_b = []\n",
    "recall_c = []\n",
    "f1_score_a = []\n",
    "f1_score_b = []\n",
    "f1_score_c = []\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    # 모델 변경\n",
    "    \n",
    "    #훈련셋으로 RandomForest 훈련\n",
    "    rf=RandomForestClassifier(random_state=0)\n",
    "    rf.fit(X_train,y_train)\n",
    "    #테스트셋을 가지고 성능 확인\n",
    "    y_predict=rf.predict(X_test)\n",
    "    \n",
    "    acc, prec_a, prec_b, prec_c, rec_a, rec_b, rec_c, f1_a, f1_b, f1_c = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision_a.append(prec_a)\n",
    "    precision_b.append(prec_b)\n",
    "    precision_c.append(prec_c)\n",
    "    recall_a.append(rec_a)\n",
    "    recall_b.append(rec_b)\n",
    "    recall_c.append(rec_c)\n",
    "    f1_score_a.append(f1_a)\n",
    "    f1_score_b.append(f1_b)\n",
    "    f1_score_c.append(f1_c)\n",
    "\n",
    "import statistics\n",
    "print(\"\\naverage_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"A\")\n",
    "print(\"average_precision = \",statistics.mean(precision_a))\n",
    "print(\"average_recall = \",statistics.mean(recall_a))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_a))\n",
    "print(\"B\")\n",
    "print(\"average_precision = \",statistics.mean(precision_b))\n",
    "print(\"average_recall = \",statistics.mean(recall_b))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_b))\n",
    "print(\"C\")\n",
    "print(\"average_precision = \",statistics.mean(precision_c))\n",
    "print(\"average_recall = \",statistics.mean(recall_c))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일 읽어서 sql파일에 넣기\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "def load_db_score_data():\n",
    "    xlfile = './datascience/db_score_3_labels.xlsx'\n",
    "    db_score = pd.read_excel(xlfile)\n",
    "    \n",
    "    #db connection 생성\n",
    "    conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    #겹칠 경우\n",
    "    drop_sql = \"\"\"drop table if exists db_score\"\"\"\n",
    "    curs.execute(drop_sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    #직접 데이터프레임으로부터 테이블을 만들고 입력 하는 모듈\n",
    "    import sqlalchemy\n",
    "    database_username = 'root'\n",
    "    database_password = 'taeyoon!'\n",
    "    database_ip = 'localhost'\n",
    "    database_name = 'datascienceassignment4'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format(database_username,database_password,database_ip,database_name))\n",
    "    \n",
    "    #iris 테이블 생성 + 데이터 입력\n",
    "    db_score.to_sql(con=database_connection, name='db_score',if_exists='replace')\n",
    "load_db_score_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "\n",
    "    conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment4')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    sql=\"select * from db_score\"\n",
    "    curs.execute(sql)\n",
    "\n",
    "    #fetchone이 메모리요소에서 보면 바람직하나 데이터양이 적어 fetchall사용\n",
    "    data=curs.fetchall()\n",
    "\n",
    "    #불러오는법\n",
    "    #print(data)\n",
    "\n",
    "    curs.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 19.37, 0, 35.0), (2, 20.0, 0, 34.12), (3, 19.37, 0, 34.3), (4, 18.12, 2, 31.5), (5, 20.0, 2, 33.25), (6, 19.37, 0, 24.5), (7, 19.37, 2, 23.8), (8, 16.87, 0, 28.87), (9, 19.37, 0, 29.75), (10, 20.0, 0, 31.5), (11, 19.37, 0, 29.57), (12, 19.37, 0, 31.5), (13, 19.37, 0, 29.75), (14, 20.0, 0, 31.5), (15, 18.12, 0, 28.0), (16, 19.37, 0, 24.5), (17, 20.0, 0, 30.62), (18, 19.37, 0, 30.62), (19, 19.37, 0, 24.5), (20, 19.37, 0, 28.0), (21, 19.37, 0, 35.0), (22, 16.87, 0, 35.0), (23, 19.37, 0, 29.75), (24, 19.37, 0, 28.0), (25, 19.37, 2, 35.0), (26, 16.87, 0, 30.45), (27, 19.37, 2, 22.75), (28, 19.37, 0, 35.0), (29, 16.25, 0, 26.25), (30, 16.87, 0, 28.0), (31, 15.0, 0, 28.87), (32, 20.0, 0, 30.62), (33, 19.37, 0, 23.45), (34, 20.0, 2, 26.25), (35, 18.12, 0, 28.0), (36, 20.0, 0, 28.0), (37, 16.87, 0, 24.5), (38, 20.0, 0, 25.37), (39, 13.75, 0, 33.25), (40, 20.0, 2, 24.5), (41, 19.37, 0, 24.5), (42, 19.37, 0, 22.75), (43, 19.37, 0, 22.57), (44, 17.5, 0, 29.75), (45, 19.37, 0, 30.62), (46, 19.37, 0, 24.5), (47, 20.0, 0, 29.75), (48, 16.87, 0, 19.25), (49, 16.87, 0, 27.82), (50, 19.37, 0, 25.37), (51, 18.75, 0, 33.25), (52, 17.5, 2, 22.75), (53, 15.62, 0, 21.0), (54, 19.37, 0, 24.5), (55, 17.5, 0, 18.37), (56, 20.0, 0, 19.25), (57, 16.87, 0, 26.25), (58, 20.0, 0, 28.87), (59, 17.5, 0, 23.8), (60, 19.37, 0, 26.25), (61, 19.37, 0, 21.0), (62, 19.37, 0, 21.0), (63, 19.37, 0, 21.17), (64, 20.0, 0, 24.5), (65, 16.87, 0, 21.7), (66, 19.37, 2, 21.87), (67, 19.37, 0, 15.75), (68, 19.37, 0, 17.5), (69, 19.37, 2, 14.87), (70, 16.87, 0, 21.0), (71, 16.87, 0, 15.75), (72, 19.37, 0, 19.25), (73, 19.37, 0, 24.5), (74, 19.37, 2, 22.75), (75, 16.25, 0, 24.5), (76, 19.37, 0, 12.25), (77, 15.62, 0, 16.62), (78, 15.0, 0, 15.05), (79, 16.87, 0, 11.9), (80, 16.87, 0, 22.05), (81, 18.12, 0, 10.5), (82, 20.0, 0, 12.95), (83, 19.37, 0, 13.12), (84, 18.75, 0, 17.5), (85, 19.37, 0, 14.0), (86, 18.75, 0, 6.12), (87, 19.37, 0, 11.37), (88, 20.0, 0, 9.62), (89, 19.37, 0, 6.12), (90, 18.75, 0, 3.5), (91, 0.0, 0, 3.5), (92, 5.0, 0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "#딕셔너리 형태가 튜플 형태의 리스트로 바뀐다.\n",
    "X=[(t['sno'],t['homework'],t['discussion'],t['midterm'])for t in data]\n",
    "print(X)\n",
    "\n",
    "\n",
    "#print(type(X)) - <class 'list'>\n",
    "#print(type(X[0])) - <class 'tuple'>\n",
    "\n",
    "#tuple의 리스트가 numpy로 바뀐다.\n",
    "X=np.array(X)\n",
    "#print(X)\n",
    "\n",
    "#print(X.shape) - (150, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "y=[1 if (t['grade']=='B') else -1 for t in data]\n",
    "y=np.array(y)\n",
    "print(y)\n",
    "#print(y.shape) - (150,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
      "  1 -1 -1 -1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "#train data와 test data분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test_size=0.33 - train데이터(7)와 test data(3)를 7대3으로 나눈다\n",
    "#random_state=42 data를 섞는다\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.33, random_state=42) #보통 42로 고정\n",
    "\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "#모델 생성\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree_model = dtree.fit(X_train, y_train) \n",
    "\n",
    "#예측 값\n",
    "y_predict = dtree_model.predict(X_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.967742\n",
      "precision=1.000000\n",
      "recall=0.888889\n",
      "f1_score=0.941176\n"
     ]
    }
   ],
   "source": [
    "#성능 측정\n",
    "def classification_performance_eval(y,y_predict):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for y, yp in zip(y,y_predict) :\n",
    "            if (y == 1 and yp == 1):\n",
    "                tp += 1\n",
    "            elif(y == 1 and yp == -1):\n",
    "                fn += 1\n",
    "            elif(y== -1 and yp == 1) : \n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = (tp)/(tp+fp)\n",
    "    recall = (tp) / (tp+fn)\n",
    "    f1_score = 2*precision*recall / (precision + recall)\n",
    "    \n",
    "    return accuracy,precision,recall,f1_score\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict)\n",
    "\n",
    "print(\"accuracy=%f\"%acc)\n",
    "print(\"precision=%f\"%prec)\n",
    "print(\"recall=%f\"%rec)\n",
    "print(\"f1_score=%f\"%f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확한 성능 구하기\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "accuracy= []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "#n_splits값을 너무 작게 train이 충분히 안된다.\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    \n",
    "    dtree = tree.DecisionTreeClassifier()\n",
    "    dtree = dtree_model.fit(X_train,y_train)\n",
    "    y_predict = dtree_model.predict(X_test)\n",
    "    acc, prec, rec, f1 = classification_performance_eval(y_test,y_predict) \n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "    \n",
    "#print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy =  0.967251461988304\n",
      "average_precision =  0.9818181818181818\n",
      "average_recall =  0.9314285714285714\n",
      "average_f1_score =  0.9528693528693528\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print(\"average_accuracy = \",statistics.mean(accuracy))\n",
    "print(\"average_precision = \",statistics.mean(precision))\n",
    "print(\"average_recall = \",statistics.mean(recall))\n",
    "print(\"average_f1_score = \",statistics.mean(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
