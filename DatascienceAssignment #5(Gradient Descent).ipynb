{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.773\n",
      "Model:                            OLS   Adj. R-squared:                  0.771\n",
      "Method:                 Least Squares   F-statistic:                     306.8\n",
      "Date:                Mon, 26 Oct 2020   Prob (F-statistic):           9.65e-31\n",
      "Time:                        20:53:58   Log-Likelihood:                -312.21\n",
      "No. Observations:                  92   AIC:                             628.4\n",
      "Df Residuals:                      90   BIC:                             633.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         24.3479      2.390     10.186      0.000      19.599      29.097\n",
      "x1             1.6848      0.096     17.515      0.000       1.494       1.876\n",
      "==============================================================================\n",
      "Omnibus:                        0.944   Durbin-Watson:                   1.440\n",
      "Prob(Omnibus):                  0.624   Jarque-Bera (JB):                0.700\n",
      "Skew:                          -0.213   Prob(JB):                        0.705\n",
      "Kurtosis:                       3.034   Cond. No.                         78.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "epoch 0: m_grad=-3227.859378, c_grad=-128.088261, m=3.227859, c=0.128088\n",
      "epoch 1000: m_grad=0.153812, c_grad=-4.030093, m=2.439509, c=4.574169\n",
      "epoch 2000: m_grad=0.125454, c_grad=-3.287082, m=2.300372, c=8.219775\n",
      "epoch 3000: m_grad=0.102325, c_grad=-2.681057, m=2.186887, c=11.193257\n",
      "epoch 4000: m_grad=0.083460, c_grad=-2.186762, m=2.094324, c=13.618531\n",
      "epoch 5000: m_grad=0.068072, c_grad=-1.783598, m=2.018827, c=15.596667\n",
      "epoch 6000: m_grad=0.055522, c_grad=-1.454764, m=1.957249, c=17.210103\n",
      "epoch 7000: m_grad=0.045286, c_grad=-1.186555, m=1.907024, c=18.526077\n",
      "epoch 8000: m_grad=0.036937, c_grad=-0.967795, m=1.866058, c=19.599430\n",
      "epoch 9000: m_grad=0.030127, c_grad=-0.789367, m=1.832646, c=20.474894\n",
      "epoch 10000: m_grad=0.024572, c_grad=-0.643835, m=1.805393, c=21.188952\n",
      "epoch 11000: m_grad=0.020042, c_grad=-0.525134, m=1.783165, c=21.771362\n",
      "epoch 12000: m_grad=0.016347, c_grad=-0.428317, m=1.765035, c=22.246396\n",
      "epoch 13000: m_grad=0.013333, c_grad=-0.349350, m=1.750247, c=22.633850\n",
      "epoch 14000: m_grad=0.010875, c_grad=-0.284942, m=1.738186, c=22.949871\n",
      "epoch 15000: m_grad=0.008870, c_grad=-0.232408, m=1.728349, c=23.207628\n",
      "epoch 16000: m_grad=0.007235, c_grad=-0.189560, m=1.720325, c=23.417864\n",
      "epoch 17000: m_grad=0.005901, c_grad=-0.154612, m=1.713780, c=23.589339\n",
      "epoch 18000: m_grad=0.004813, c_grad=-0.126107, m=1.708442, c=23.729201\n",
      "epoch 19000: m_grad=0.003926, c_grad=-0.102857, m=1.704089, c=23.843276\n",
      "epoch 20000: m_grad=0.003202, c_grad=-0.083894, m=1.700538, c=23.936320\n",
      "epoch 21000: m_grad=0.002612, c_grad=-0.068427, m=1.697641, c=24.012210\n",
      "epoch 22000: m_grad=0.002130, c_grad=-0.055811, m=1.695279, c=24.074109\n",
      "epoch 23000: m_grad=0.001737, c_grad=-0.045521, m=1.693352, c=24.124595\n",
      "epoch 24000: m_grad=0.001417, c_grad=-0.037129, m=1.691780, c=24.165773\n",
      "epoch 25000: m_grad=0.001156, c_grad=-0.030284, m=1.690498, c=24.199360\n",
      "epoch 26000: m_grad=0.000943, c_grad=-0.024700, m=1.689453, c=24.226754\n",
      "epoch 27000: m_grad=0.000769, c_grad=-0.020146, m=1.688600, c=24.249098\n",
      "epoch 28000: m_grad=0.000627, c_grad=-0.016432, m=1.687905, c=24.267323\n",
      "epoch 29000: m_grad=0.000512, c_grad=-0.013403, m=1.687337, c=24.282187\n",
      "epoch 30000: m_grad=0.000417, c_grad=-0.010932, m=1.686875, c=24.294311\n",
      "epoch 31000: m_grad=0.000340, c_grad=-0.008916, m=1.686497, c=24.304200\n",
      "epoch 32000: m_grad=0.000278, c_grad=-0.007272, m=1.686189, c=24.312265\n",
      "epoch 33000: m_grad=0.000226, c_grad=-0.005932, m=1.685938, c=24.318844\n",
      "epoch 34000: m_grad=0.000185, c_grad=-0.004838, m=1.685733, c=24.324209\n",
      "epoch 35000: m_grad=0.000151, c_grad=-0.003946, m=1.685566, c=24.328586\n",
      "epoch 36000: m_grad=0.000123, c_grad=-0.003219, m=1.685430, c=24.332155\n",
      "epoch 37000: m_grad=0.000100, c_grad=-0.002625, m=1.685319, c=24.335067\n",
      "epoch 38000: m_grad=0.000082, c_grad=-0.002141, m=1.685228, c=24.337442\n",
      "epoch 39000: m_grad=0.000067, c_grad=-0.001746, m=1.685154, c=24.339378\n",
      "epoch 40000: m_grad=0.000054, c_grad=-0.001424, m=1.685094, c=24.340958\n",
      "epoch 41000: m_grad=0.000044, c_grad=-0.001162, m=1.685045, c=24.342247\n",
      "epoch 42000: m_grad=0.000036, c_grad=-0.000948, m=1.685005, c=24.343298\n",
      "epoch 43000: m_grad=0.000029, c_grad=-0.000773, m=1.684972, c=24.344155\n",
      "epoch 44000: m_grad=0.000024, c_grad=-0.000630, m=1.684946, c=24.344854\n",
      "epoch 45000: m_grad=0.000020, c_grad=-0.000514, m=1.684924, c=24.345424\n",
      "epoch 46000: m_grad=0.000016, c_grad=-0.000419, m=1.684906, c=24.345889\n",
      "epoch 47000: m_grad=0.000013, c_grad=-0.000342, m=1.684892, c=24.346269\n",
      "epoch 48000: m_grad=0.000011, c_grad=-0.000279, m=1.684880, c=24.346578\n",
      "epoch 49000: m_grad=0.000009, c_grad=-0.000228, m=1.684870, c=24.346831\n",
      "epoch 50000: m_grad=0.000007, c_grad=-0.000186, m=1.684862, c=24.347037\n",
      "epoch 51000: m_grad=0.000006, c_grad=-0.000151, m=1.684856, c=24.347204\n",
      "epoch 52000: m_grad=0.000005, c_grad=-0.000123, m=1.684851, c=24.347341\n",
      "epoch 53000: m_grad=0.000004, c_grad=-0.000101, m=1.684846, c=24.347453\n",
      "26.075281 seconds\n",
      "\n",
      "\n",
      "Final:\n",
      "gdn_m=1.684846, gdn_c=24.347457\n",
      "ls_m=1.684827, ls_c=24.347947\n"
     ]
    }
   ],
   "source": [
    "#simple linear regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql\n",
    "import time\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "def load_dbscore_data():\n",
    "    conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment2')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "    sql = \"select * from db_score\"\n",
    "    curs.execute(sql)\n",
    "    \n",
    "    data  = curs.fetchall()\n",
    "    \n",
    "    curs.close()\n",
    "    conn.close()\n",
    "    \n",
    "    #X = [ (t['attendance'], t['homework'], t['midterm'] ) for t in data ]\n",
    "    X = [ ( t['midterm'] ) for t in data ]\n",
    "    X = np.array(X)\n",
    "    \n",
    "    y = [ (t['score']) for t in data]\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = load_dbscore_data()\n",
    "\n",
    "# y = mx + c\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from celluloid import Camera\n",
    "fig = plt.figure()\n",
    "ax = fig.subplots()\n",
    "\n",
    "camera = Camera(fig)\n",
    "x = np.linspace(0, 2 * np.pi)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X_const)\n",
    "ls = model.fit()\n",
    "\n",
    "print(ls.summary())\n",
    "\n",
    "\n",
    "ls_c = ls.params[0]\n",
    "ls_m = ls.params[1]\n",
    "\n",
    "c=ls_c\n",
    "m=ls_m\n",
    "\n",
    "y_pred = m*X + c\n",
    "\n",
    "#plt.scatter(X, y) \n",
    "#plt.plot([min(X), max(X)], [min(y_pred), max(y_pred)], color='red')\n",
    "#plt.show()\n",
    "\n",
    "def gradient_descent_naive(X, y):\n",
    "\n",
    "    epochs = 100000\n",
    "    min_grad = 0.0001\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    m = 0.0\n",
    "    c = 0.0\n",
    "    \n",
    "    n = len(y)\n",
    "    \n",
    "    c_grad = 0.0\n",
    "    m_grad = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i in range(n):\n",
    "            y_pred = m * X[i] + c\n",
    "            m_grad += 2*(y_pred-y[i]) * X[i]\n",
    "            c_grad += 2*(y_pred - y[i])\n",
    "\n",
    "        c_grad /= n\n",
    "        m_grad /= n\n",
    "        \n",
    "        m = m - learning_rate * m_grad\n",
    "        c = c - learning_rate * c_grad\n",
    "        \n",
    "        y_pred /= n\n",
    "        \n",
    "        if ( epoch % 1000 == 0):\n",
    "            print(\"epoch %d: m_grad=%f, c_grad=%f, m=%f, c=%f\" %(epoch, m_grad, c_grad, m, c) ) \n",
    "            \n",
    "            ax.scatter(X, y) \n",
    "            ax.plot([min(X), max(X)], [min(m*X+c), max(m*X+c)])\n",
    "            plt.show()\n",
    "            camera.snap()\n",
    "        \n",
    "        if ( abs(m_grad) < min_grad and abs(c_grad) < min_grad ):\n",
    "            break\n",
    "        \n",
    "    return m, c\n",
    "\n",
    "start_time = time.time()\n",
    "m, c = gradient_descent_naive(X, y)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"%f seconds\" %(end_time - start_time))\n",
    "\n",
    "print(\"\\n\\nFinal:\")\n",
    "print(\"gdn_m=%f, gdn_c=%f\" %(m, c) )\n",
    "print(\"ls_m=%f, ls_c=%f\" %(ls_m, ls_c) )\n",
    "\n",
    "animation = camera.animate(interval=50, blit=True)\n",
    "#animation.save('gradient descent.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#multiple linear regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql\n",
    "import time\n",
    "\n",
    "def load_dbscore_data():\n",
    "    conn = pymysql.connect(host = 'localhost',user = 'root',password = 'taeyoon!', db = 'datascienceassignment2')\n",
    "    curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "    sql = \"select * from db_score\"\n",
    "    curs.execute(sql)\n",
    "    \n",
    "    data  = curs.fetchall()\n",
    "    \n",
    "    curs.close()\n",
    "    conn.close()\n",
    "    \n",
    "    X = [ ( t['attendance'],t['homework'],t['midterm'] ) for t in data ]\n",
    "    X = np.array(X)\n",
    "    \n",
    "    y = [ (t['score']) for t in data]\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = load_dbscore_data()\n",
    "X1, X2, X3 = np.hsplit(X, 3) #3개의 배열로 분리\n",
    "\n",
    "import statsmodels.api as sm #Least Square\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X_const)\n",
    "ls = model.fit()\n",
    "\n",
    "print(ls.summary())\n",
    "\n",
    "ls_c = ls.params[0]\n",
    "ls_m1 = ls.params[1]\n",
    "ls_m2 = ls.params[2]\n",
    "ls_m3 = ls.params[3]\n",
    "\n",
    "def gradient_descent_vectorized(X, y):\n",
    "    #epochs = 100000\n",
    "    epochs = 1000000\n",
    "    min_grad = 0.0001\n",
    "    #learning_rate = 0.001\n",
    "    learning_rate = 0.00001\n",
    "    \n",
    "    m1 = 0.0\n",
    "    m2 = 0.0\n",
    "    m3 = 0.0\n",
    "    c = 0.0\n",
    "    \n",
    "    n = len(y)\n",
    "    \n",
    "    c_grad = 0.0\n",
    "    m1_grad = 0.0\n",
    "    m2_grad = 0.0\n",
    "    m3_grad = 0.0\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):    \n",
    "       \n",
    "        y_pred = (m1*X1) + (m2*X2) + (m3*X3) + c #X를 통으로 집어넣는다\n",
    "        m1_grad = (2*(y_pred - y)*X1).sum()/n # 한번에 계산\n",
    "        m2_grad = (2*(y_pred - y)*X2).sum()/n # 한번에 계산\n",
    "        m3_grad = (2*(y_pred - y)*X3).sum()/n # 한번에 계산\n",
    "        c_grad = (2*(y_pred - y)).sum()/n\n",
    "        m1 = m1 - learning_rate * m1_grad\n",
    "        m2 = m2 - learning_rate * m2_grad\n",
    "        m3 = m3 - learning_rate * m3_grad\n",
    "        c = c - learning_rate * c_grad    \n",
    "        \n",
    "        if ( epoch % 1000 == 0):\n",
    "            print(\"epoch %d: m1_grad=%f, m2_grad=%f, m3_grad=%f, c_grad=%f \" %(epoch, m1_grad, m2_grad, m3_grad, c_grad) )\n",
    "            print(\"m1=%f, m2=%f, m3=%f, c=%f \\n\" %(m1,m2,m3,c))\n",
    "    \n",
    "        if ( abs(m1_grad) < min_grad and abs(m2_grad) < min_grad and abs(m3_grad) < min_grad and  abs(c_grad) < min_grad ):\n",
    "            break\n",
    "\n",
    "    return m1,m2,m3,c\n",
    "\n",
    "start_time = time.time()\n",
    "m1,m2,m3, c = gradient_descent_vectorized(X, y)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"%f seconds\" %(end_time - start_time))\n",
    "\n",
    "print(\"\\n\\nFinal:\")\n",
    "print(\"gdv_m1=%f, gdv_m2=%f, gdv_m3=%f, gdv_c=%f\" %(m1,m2,m3,c) )\n",
    "print(\"ls_m1=%f, ls_m2=%f, ls_m3=%f, ls_c=%f\" %(ls_m1,ls_m2,ls_m3, ls_c) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
